<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>dfa.io</title>
 <link href="http://dfa.io/atom.xml" rel="self"/>
 <link href="http://dfa.io/"/>
 <updated>2015-04-15T15:27:11-05:00</updated>
 <id>http://dfa.io</id>
 <author>
   <name>Evan Bergeron</name>
   <email>ebergeron@cmu.edu</email>
 </author>

 
 <entry>
   <title>Edge Connectivity, Quickly</title>
   <link href="http://dfa.io//2015/04/15/edge-connectivity-quickly/"/>
   <updated>2015-04-15T00:00:00-05:00</updated>
   <id>http://dfa.io/2015/04/15/edge-connectivity-quickly</id>
   <content type="html">&lt;p&gt;Today we’ll talk about another randomized algorithm: this time to find the edge connectivity of a graph. We’ll present a naive solution first and then discuss a dramatic improvement. This should serve as a nice introduction to Monte Carlo randomized algorithms :)&lt;/p&gt;

&lt;p&gt;If you’ve seen the naive solution before, feel free to skip down the “An Improvement” section, where we discuss the Karger-Stein algorithm.&lt;/p&gt;

&lt;h3 id=&quot;some-definitions&quot;&gt;Some Definitions&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;edge-connectivity&lt;/em&gt; of a graph is the largest number $k$ such that upon removal of any subset of edges of $E$ of size less than $k$, $G$ remains connected. So a tree has edge-connectivity 1. A graph that is a cycle has edge-connectivity 2.&lt;/p&gt;

&lt;p&gt;We also define the &lt;em&gt;min-cut problem&lt;/em&gt;: given a graph $G = (V, E)$, find a nonempty subset $S \subset V$ such that the number of edges from $S$ to $V-S$ is minimized.&lt;/p&gt;

&lt;p&gt;So then we have the min-cut problem solves the edge-connectivity question. Presenting a smallest cut means that, for any set of edges smaller than our cut, removal of that subset from $G$ preserves $G$ connectednss. Which is precisely edge-connectivity!&lt;/p&gt;

&lt;h3 id=&quot;our-algorithm&quot;&gt;Our Algorithm&lt;/h3&gt;
&lt;p&gt;Some quick python-esque pseudocode:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mincut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# delete self loops&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges_remaining&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let’s do some analysis on this algorithm’s probability of correctness.&lt;/p&gt;

&lt;p&gt;Suppose we have some graph $G = (V, E)$ be a graph with $n$ vertices. Let $F$ be some min cut of $G$. Then we claim that the probability that $\texttt{mincut}$ outputs $F$ is at least $\frac{2}{n(n-1)}$.&lt;/p&gt;

&lt;p&gt;To show this, we’ll lower bound the probability that $\texttt{mincut}$ is wrong.&lt;/p&gt;

&lt;p&gt;Let’s define some variables: let $\mid F\mid = k$, $\mid V\mid = n$ and $\mid E \mid = m$.&lt;/p&gt;

&lt;p&gt;We make the following observation: if our contraction algorithm ever contracts something in $F$, then we won’t choose $F$ as a cut. Conversely, if our algorithm never picks something in $F$, then certainly, the cut we’re left with will be $F$.&lt;/p&gt;

&lt;p&gt;So Pr(We pick $F$ as our min cut) = Pr(We never contract an edge in $F$).&lt;/p&gt;

&lt;p&gt;Let’s define $E_i$ to the event that our algo contracts an edge in $F$ in iteration $i$. So we’re considering&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Pr(\bar{E_1} \cap \ldots \cap \bar{E_{n-2}})&lt;/script&gt;

&lt;p&gt;(Note the $n-2$. We only go until we have two vertices left).
Using the definition of conditional probability, we can see that the above is the same as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Pr(\bar{E_1}) \cdot \Pr(\bar{E_2}|\bar{E_1}) \cdots \Pr(\bar{E_{n-2}}|\bar{E_1} \cap \bar{E_2} \cdots \cap \bar{E_{n-3}})&lt;/script&gt;

&lt;p&gt;Though this looks gross, we’ll be able to establish lower bounds on each of the terms individually. Let’s start with the first term.&lt;/p&gt;

&lt;p&gt;We started with the assumption that we had a min cut $F$ and it was of size $k$. So then every vertex in $G$ must have degree at least $k$, as otherwise, we could pick the edges to which it’s incident and have a smaller cut. So this means that $2m = \sum_{v \in V} deg(v) \geq kn$. Or in other words, $\frac{k}{m} \leq \frac{2}{n}$.&lt;/p&gt;

&lt;p&gt;But we have that $\Pr(E_1)$ (the prob that we pick a guy in $F$ in our first run) is $\frac{k}{n} \leq \frac{2}{n}$. So then $\Pr(\bar{E_1}) \geq (1 - \frac{2}{n})$.&lt;/p&gt;

&lt;p&gt;So that’s not so bad. We then have a bound on the first term in that ugly product we had. Let’s keep going.&lt;/p&gt;

&lt;p&gt;Let’s consider the $i$th iteration. Let’s suppose that up until now, we’ve been kosher. Which is to say, we haven’t picked anything in $F$ yet. Things are going great. What’s the probability we keep it going?&lt;/p&gt;

&lt;p&gt;Well, we have $k$ edges in our min cut and some number of remaining edges $m’$. So then the probability we don’t mess up is $1 - \frac{k}{m’}$. But we want some bound of this in terms of $n$…&lt;/p&gt;

&lt;p&gt;Well, let’s think. Here’s an observation: at &lt;em&gt;every&lt;/em&gt; point in the algorithm, every vertex must have degree at least $k$. To see this, remember that each vertex now represents some clump of vertices. If some vertex had degree less than $k$, then there would be some clump of vertices that could be seperated by removing less than $k$ vertices. But that would contradict our assumption that $F$ is a min cut!&lt;/p&gt;

&lt;p&gt;So after $i$ contractions, by the handshaking lemma, we have that $m’ \geq \frac{k(n-i)}{2}$, where $m’$ is the number of remaining edges.&lt;/p&gt;

&lt;p&gt;So then the probability that we screw up in the $i$th iteration, given that we’d been fine so far is at least&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;1 - \frac{k}{m&#39;} \geq 1 - \frac{k}{k(n-i)/2} = 1 - \frac{2}{n-i}&lt;/script&gt;

&lt;p&gt;So then, the big probability mess we had above is at least
  &lt;script type=&quot;math/tex&quot;&gt;\left(1 - \frac{2}{n}\right)
  \left(1 - \frac{2}{n-2}\right)\cdots \left(1 - \frac{2}{n-(n-3)}\right)
  =
  \left(\frac{n-2}{n}\right)
  \left(\frac{n-3}{n-1}\right)\cdots
  \left(\frac{2}{4}\right)
  \left(\frac{1}{3}\right)&lt;/script&gt;
But cancelling terms, we get that this is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{2}{n(n-1)}&lt;/script&gt;

&lt;p&gt;As claimed. But wait a second. That probability is the probability of correctness. Which is $\Omega(n^{-2})$.&lt;/p&gt;

&lt;p&gt;I’m not sure we should be impressed.&lt;/p&gt;

&lt;p&gt;Sure, this algorithm is polytime, but it’s probability of correctness is abyssmal! Luckily, we’re about to see a really useful tool in randomized algorithms. It’s called &lt;em&gt;amplification&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;amplification&quot;&gt;Amplification&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Amplification&lt;/em&gt; - running an randomized algorithm a lot of times to decrease its probability of error.&lt;/p&gt;

&lt;p&gt;So instead, let’s try running the new randomized algorithm lots of times (say, $t$ times) and choose the smallest of the cuts we get. So then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Pr(\text{Missing our min cut}) = \Pr(\text{original algo missing min cut})^t&lt;/script&gt;

&lt;p&gt;Then
&lt;script type=&quot;math/tex&quot;&gt;\left(1 - \frac{2}{n(n-1)}\right)^t \leq \left(1 - \frac{1}{n^2}\right)^t.&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Note than when $t = n^2$, this goes to $\frac{1}{e}$. When $t = n^3$, this goes to $\frac{1}{e^n}$, which is tiny! Note that this is running the original algorithm $n^3$ times. We contracted order $n^2$ edges, so to get this probability bound, our overall big oh cost is $O(n^5)$. So if we’re willing to wait around for a while, then we can be &lt;em&gt;almost guaranteed&lt;/em&gt; that our algorithm is correct! And all in polytime :)&lt;/p&gt;

&lt;h3 id=&quot;an-improvement&quot;&gt;An Improvement&lt;/h3&gt;

&lt;p&gt;The probability we had originally was a product of things. And at the very end, those things got pretty small. Three quarters? A third? These terms our killing our probability of correctness!&lt;/p&gt;

&lt;p&gt;Which sparks a new idea. Maybe we should use the original contracting idea for a while, but once $G$ starts to get pretty small, switch to something a bit slower. It’ll be a small sacrifice in time, but perhaps we’ll save on the number of times we need to repeat the algorithm.&lt;/p&gt;

&lt;p&gt;So let’s try it! We’ll to establish a cutoff point - any probability higher than this will be considered “bad.” For our purposes, a half should be fine. So when do we need to stop contracting? It turns out that if we contract the graph until it has $\frac{n}{\sqrt{2}}$ remaining vertices (starting with $n$), then any contraction after that has more than a 50/50 chance of ruining our min cut.&lt;/p&gt;

&lt;p&gt;Check it out:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prod_{i=n/\sqrt{2}}^n \frac{i-2}{i} = \frac{n/\sqrt{2}(n/\sqrt{2} - 1)}{n(n-1)} \approx \frac{(n/\sqrt{2})^2}{n^2} \approx \frac{1}{2}&lt;/script&gt;

&lt;p&gt;(If that looks like a giant mess, don’t worry about it. The terms in the product cancel out as they did before).&lt;/p&gt;

&lt;p&gt;So we first contract down to $n/\sqrt{2}$ vertices. Now what? Well now we need to tread carefully, because we have at least a half chance to mess up our min cut. So we make a couple of tries. We’ll pick two different edges and continue onward from there, taking the minimum of the two min cuts provided to us. Not only that, we’ll use this strategy multiple times, recursively. When we get to some small number of vertices, we can use a slower algorithm to give us the best min-cut on some small graph.&lt;/p&gt;

&lt;p&gt;So we have&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;contract_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;faster_mincut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertex_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;careful_mincut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertex_set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;G1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contract_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;G2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;contract_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;faster_mincut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;faster_mincut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;analysis---correctness&quot;&gt;Analysis - Correctness&lt;/h3&gt;

&lt;p&gt;So what has this gained us? Quite a bit, actually. Let’s call $P(n)$ the probability of picking a fixed mincut on $n$ vertices. Let’s consider the probability that one of the recursive calls picks a particular mincut. Call this probability $P_{X1}$.So then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_{X1} = P_{X2} \leq \frac{1}{2} \cdot P\left(\frac{n}{\sqrt{2}}\right)&lt;/script&gt;

&lt;p&gt;Our overall algorithm will return the proper mincut if it doesn’t select any edge in the recursive calls. So then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(n) = 1 - (1 - P_{X1})(1 - P_{X2})&lt;/script&gt;

&lt;p&gt;Which together yield&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(n) \geq P\left(\frac{n}{\sqrt{2}}\right) + \frac{1}{4}P\left(\frac{n}{\sqrt{2}}\right)^2&lt;/script&gt;

&lt;p&gt;This has solution $O(\frac{1}{lg(n)})$ (proof by induction).&lt;/p&gt;

&lt;h3 id=&quot;analysis---runtime&quot;&gt;Analysis - Runtime&lt;/h3&gt;

&lt;p&gt;Each call of $\texttt{faster_mincut}$ makes two recursive calls and contracts some edges. The number of edge contractions is a constant multiple of the number of edges, so is $O(n^2)$. So our recurrence for work is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;T(n) = 2T\left(\frac{n}{\sqrt{2}}\right) + O(n^2)&lt;/script&gt;

&lt;p&gt;By the master theorem, this is $O(n^2lg(n))$.&lt;/p&gt;

&lt;h3 id=&quot;more-amplification&quot;&gt;More Amplification&lt;/h3&gt;

&lt;p&gt;So what does it take to get our same $1 - \frac{1}{e^n}$ bound of correctness? It turns out to be $nlg(n)$. Our probability of success works out to be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;1 - \left(1 - \frac{1}{lg(n)}\right)^{nlg(n)} = 1 - \frac{1}{e^n}&lt;/script&gt;

&lt;p&gt;So overall, we run a $O(n^2lg(n))$ algorithm $nlg(n)$ times, yielding an overall big oh of $O(n^3(lg(n))^2)$. Contrast this with the $O(n^5)$ algorithm we had originally!&lt;/p&gt;

&lt;h3 id=&quot;reflections&quot;&gt;Reflections&lt;/h3&gt;

&lt;p&gt;Hopefully this was enlightening. It’s a bit nice to see a nontrivial randomized algorithm, isn’t it?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Phone-a-Friend and SUPERHALTS</title>
   <link href="http://dfa.io//2015/04/09/Phone-A-Friend-and-SUPERHALTS/"/>
   <updated>2015-04-09T00:00:00-05:00</updated>
   <id>http://dfa.io/2015/04/09/Phone-A-Friend-and-SUPERHALTS</id>
   <content type="html">&lt;p&gt;Deciding things is hard. There are countably many Turing machines, but an uncountable number of decision problems! Sometimes, maybe asking our TM M for a decision is unreasonable - maybe sometimes we should let him phone-a-friend. A reasonable question to ask is: if our friend always gives us the right answer, is this enough?&lt;/p&gt;

&lt;p&gt;We define the phone-a-friend mechanism as follows: our TM M is given access to an &lt;em&gt;oracle&lt;/em&gt;. The TM may ask the oracle a membership question: is this string \(w\) in some set \(S\)? The oracle is all-knowing and will return a yes or no answer immediately. The oracle will always answer correctly. We call a Turing machine with access to an oracle an &lt;em&gt;oracle Turing machine&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;So certainly, all of a sudden, life gets a lot easier! For example, solving HALTS is trivial! Just ask the oracle. But here’s an interesting question: is there a decision problem that a Turing machine can’t solve, even when given an oracle to HALTS? Which is to say, is there a problem that our TM M’s friend &lt;em&gt;can’t&lt;/em&gt; know?&lt;/p&gt;

&lt;p&gt;Unfortunately, (and maybe unsurprisingly), yes. Consider this following problem, which we call \(SUPERHALTS\):&lt;/p&gt;

&lt;p&gt;\[ \{(M, x) | M\text{, with an oracle for the halting problem, halts on x}\} \]&lt;/p&gt;

&lt;p&gt;We can use the classic diagonalization argument to show that this is undecidable. Suppose we have some oracle Turing machine \(H\) that decides SUPERHALTS. Then we can define a new TM D to be:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;If&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accepts&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LOOP&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ACCEPT&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But then D(D) halts if and only if H(D, D) accepts. But H(D, D) accepts iff D(D) loops! So we have that D(D) halts if and only if it loops, a contradiction. Even if you’ve seen this argument before, take a minute and reason through that last sentence. It’s good for you.&lt;/p&gt;

&lt;p&gt;So this is interesting. We’ve found a problem that’s &lt;em&gt;harder than the halting problem&lt;/em&gt;. Significantly so. Which brings us to something called &lt;em&gt;Turing degrees&lt;/em&gt;. Computable functions have Turing degree 1. Anything reducible to the halting problem has Turing degree 2. The SUPERHALTS is our first problem with Turing greater than two.&lt;/p&gt;

&lt;p&gt;It’s interesting how coarse a measurement Turing degree really is. Obviously, it doesn’t touch notions of complexity, with no regard for the distinction between, say \(P\) and \(ELEMENTARY\). But further, it doesn’t even distinguish between Turing-decidable and Turing-recognizable! (Or if you prefer, recursively enumerable). (A Turing-recognizable set is similar to a decidable one, we just relax the restriction that the TM must halt on all inputs).&lt;/p&gt;

&lt;p&gt;So here’s another question: is there any problem of intermediate degree? Some problem that falls between HALTS and SUPERHALTS? This is known as the &lt;em&gt;Post problem&lt;/em&gt; (different from the Post Correspondence Problem). And the answer, apparently, is yes.&lt;/p&gt;

&lt;p&gt;The result involves something called a &lt;em&gt;priority ordering&lt;/em&gt;. In a priority ordering, we define some set \(X\). Then we make a (potentially infinite) list of requirements. Each of these requirements specifies whether or not some set of elements is in \(X\). So we start with, say, the universe. Then requirement 1 specifies that elements in \(X\) must have some feature. And requirement 2 does similarly. Maybe requirement \(k\) designates that some element get thrown back into \(X\). And so on.&lt;/p&gt;

&lt;p&gt;Anyway, this technique can be used to generate two problems A and B, both of which can be solved with an oracle to the halting problem, but neither can be solved with an oracle to the other! I guess you use the priority ordering technique to forbid any Turing machine that would reduce A to B or vice versa.&lt;/p&gt;

&lt;p&gt;And into the world of non-computability we go! And you thought complexity was bad…&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Randomized Quicksort</title>
   <link href="http://dfa.io//2015/03/25/randomized-quicksort/"/>
   <updated>2015-03-25T00:00:00-05:00</updated>
   <id>http://dfa.io/2015/03/25/randomized-quicksort</id>
   <content type="html">&lt;p&gt;As a nice first randomized algorithm, we’ll present a randomized version of quicksort and do some analysis on its runtime. This post assumes familiarity with basic probability concepts (mainly expectation).&lt;/p&gt;

&lt;p&gt;This algorithm will be an example of Las Vegas algorithm - a randomized algorithm whose runtime is variable, not its probability of correctness. Interestingly, Las Vegas algorithms were first coined in 1979 by a professor at University of Chicago named Laszlo Babai. In fact, Babai’s doctoral advisor was Turan! (Of Turan’s theorem in graph theory).&lt;/p&gt;

&lt;p&gt;Las Vegas algorithms are in contrast the other main type of randomized algorithm, Monte Carlo algorithms. Monte Carlo algorithms’ probability of correctness is variable, not their runtime.&lt;/p&gt;

&lt;p&gt;But first, a lightning fast review of deterministic quicksort. In deterministic quicksort, we have some list that we want to sort. We pick a pivot point and then break our list up into two parts: those elements of the list smaller than the pivot and those greater. We then recurse on these smaller lists.&lt;/p&gt;

&lt;p&gt;A quick python implementation is as follows:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;quicksort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;smaller&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;larger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quicksort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smaller&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quicksort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;larger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On average, this will run in \(O(nlgn)\), but our worst-case runtime is \(O(n^2)\). That is, if our choice of pivot happens to be the smallest or biggest of the list, we’re kinda screwed.&lt;/p&gt;

&lt;p&gt;So account for this issue, we can instead just choose a pivot at random. This can make it difficult for an adversary to feed us a worst case input. In python, this would amount to:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;randomized_quicksort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# randint upper bound is inclusive&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;smaller&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;larger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quicksort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smaller&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quicksort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;larger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Quick and easy! Let’s do some analysis on the expected runtime. When we say expected runtime, we’re taking the expectation over all choices of random pivots for some fixed input.&lt;/p&gt;

&lt;p&gt;We let \(a_1, a_1, \ldots a_n\) be some input to \(\texttt{randomized_quicksort}\) and let \(s_1, s_2, \ldots, s_n\) be the sorted version of this input. We define indicator random variables \(X_{i,j}\) which are 1 if \(a_i\), \(a_j\) are ever compared during our given run of quicksort and 0 otherwise. By linearity:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}[X] = \sum_{i=1}^{n-1}\sum_{j = i+1}^n \mathbb{E}[X_{i, j}]&lt;/script&gt;

&lt;p&gt;Since \(X_{i,j}\) is an indicator random variable, its expectation is just the probability that \(a_i\) and \(a_j\) are compared. So what is this probability? Let’s call the \(i\)th element of the (sorted) array \(e_i\) and the \(j\)th element of the array \(e_j\). Certainly, if we pick either one of those elements as a pivot, we’ll compare one to the other.&lt;/p&gt;

&lt;p&gt;We’re picking pivots at random, so we might as well think of picking pivots in the following way: take the final sorted array and throw darts randomly at it. If the dart lands on the \(k\)th spot, use \(e_k\) as the pivot point. Somewhere in the sorted array, we have the sequence
&lt;script type=&quot;math/tex&quot;&gt;e_i, e_{i+1}, \ldots e_{j-1}, e_j&lt;/script&gt;
If we pick a pivot outside of this chunk of the sorted array, we just throw another dart. If throw a pivot inside this chunk and it hits \(e_i\) or \(e_j\), the two get compared. But if we pick somewhere in the middle, \(e_i\) and \(e_j\) will get moved to seperate sublists and never be compared. So the probability that \(X_{i,j}\) is 1 is
&lt;script type=&quot;math/tex&quot;&gt;\frac{2}{j-i+1}&lt;/script&gt;
So then we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}[X] = \sum_{i=1}^{n-1}\sum_{j = i+1}^n \mathbb{E}[X_{i, j}] = \sum_{i=1}^{n-1}\sum_{j = i+1}^n \frac{2}{j - i + 1}&lt;/script&gt;

&lt;p&gt;Substituting in, we see this is equal to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2\sum_{i=1}^{n-1}\sum_{k=2}^{n-i+1} \frac{1}{k}
\leq 2\sum_{i=1}^{n}\sum_{k=2}^{n} \frac{1}{k}&lt;/script&gt;

&lt;p&gt;Then, we have that the inside sum is less than \(lnn\). This can be seen by examining the integral of \(lnn\) and the viewing the sum as a Riemann sum underneath the curve. So then we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2\sum_{i=1}^{n}\sum_{k=2}^{n} \frac{1}{k} \leq 2\sum_{i=1}^{n} ln(n) \leq 2nln(n)&lt;/script&gt;

&lt;p&gt;So then we have that our randomized quicksort algorithm runs in $O(nlgn)$ as desired. :)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A Turing Machine Quine</title>
   <link href="http://dfa.io//2015/03/13/a-turing-machine-quine/"/>
   <updated>2015-03-13T00:00:00-05:00</updated>
   <id>http://dfa.io/2015/03/13/a-turing-machine-quine</id>
   <content type="html">&lt;p&gt;Today, we’ll talk about something quite exciting. We define a Turing machine that prints its own source code. This construction offers us insight into how one may construct quines in any programming language.&lt;/p&gt;

&lt;p&gt;First, some quick definitions. A &lt;em&gt;quine&lt;/em&gt; is a program that prints itself. At first this may seem impossible! A first attempt in python may look something like&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;print&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But wait. We missed the first print. So perhaps we’ll add another print? But then we have&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;print &amp;#39;print&amp;#39;&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and we have the problem we started with. Let’s revisit this is a moment.&lt;/p&gt;

&lt;p&gt;A &lt;em&gt;Turing machine&lt;/em&gt; is an abstraction of a computer. It has some finite number of states, transitions between those states, and infinite memory. Excitingly, this turns out to be a quite reasonable definition of computation. There’s a very important result in computer science called the Church-Turing Thesis, which basically says that anything your-programming-language-here can do, so can a Turing machine.&lt;/p&gt;

&lt;p&gt;Consequently, offering a Turing machine quine is a way of offering a quine for every programming language! We’ll find that it’s actually quite instructive to talk about quines in the abstract first, before moving into specific programming languages.&lt;/p&gt;

&lt;p&gt;Right. So let’s get started. We present the following lemma:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;There is a computable function \(q\), where if \(w\) is some string, \(q(w)\) is a description of a Turing machine that prints out \(w\) and halts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We offer the following TM as a construction of this function:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;On input string w:&lt;/span&gt;
    &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Construct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;following&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;P_w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;On any input:&lt;/span&gt;
            &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Erase&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;
            &lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Write&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tape&lt;/span&gt;
            &lt;span class=&quot;mf&quot;&gt;3.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Halt&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P_w&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The distinction between \(q\) the function and Q the Turing machine can be a bit subtle. \(q\) is function that maps strings to Turing machines. Q (the Turing machine) is the result of applying \(q\) (the function) to \(w\). That is, Q = \(q(w)\).&lt;/p&gt;

&lt;p&gt;So our TM Q takes a string w and outputs a TM that prints w. Perfect! Exactly what we wanted. Let’s come back to this - we’ll see why this is useful in a moment.&lt;/p&gt;

&lt;p&gt;With this lemma in hand, we proceed to the main task: building a TM that prints itself. We’ll split the machine up into two parts - A and B. First A will run, then B. Let’s start with a description for A.&lt;/p&gt;

&lt;p&gt;A’s description depends on B, so let’s assume we’ve written B. Remember the function \(q\) we just defined? We define A to be \(q(B)\). Which is to say, A is just a TM that, on any input, just prints a description of part B. This depends on our definition of B, so let’s talk about that now.&lt;/p&gt;

&lt;p&gt;B’s the second and last part of the program, so at the end, we should have printed a full description of AB. By the time we get to B, A just ran, leaving a copy of B’s source code sitting on the tape. Which means at this point, B has a description of itself. So then how do we get a description of A?&lt;/p&gt;

&lt;p&gt;Here’s the trick: we apply \(q\) to our description of B. By our definition, \(q(B)\) is a TM that, on any input, prints a copy of B. This was exactly our definition of part A!  So B takes its own source code and applies \(q\) to it, obtaining a description of A. Then B outputs AB, completing the proof.&lt;/p&gt;

&lt;p&gt;To summarize:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;QUINE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;On input string w:&lt;/span&gt;
    &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# A Turing machine that always prints B&lt;/span&gt;
    &lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;On input M, where M is a part of a TM:&lt;/span&gt;
        &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Using this proof as a template, let’s consider how we would write a quine in python. As before, let’s consider part A first. Part A needs to give B a copy of B’s source code. In the TM model, this was achieved by leaving a copy of B’s description on the tape.&lt;/p&gt;

&lt;p&gt;In python, we can just assign into a variable to achieve the same effect. So our part A should look something like&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;b&amp;#39;s source code here&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Part B should print part A and then print part B. Something like:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;b = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Print part A&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;             &lt;span class=&quot;c&quot;&gt;# Then print part B&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Combining these two together (along with some careful tiptoe-ing around python formatting) yields:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;print &amp;quot;b = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot; % b; print b&amp;#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;b = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And there you have it! A general guideline to make quines followed by an example. You are now equipped to go out and impress all your friends with your quine-making abilities. :P&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Defining Variables Inside Expressions in Python</title>
   <link href="http://dfa.io//2015/03/09/defining-variables-inside-expressions/"/>
   <updated>2015-03-09T00:00:00-05:00</updated>
   <id>http://dfa.io/2015/03/09/defining-variables-inside-expressions</id>
   <content type="html">&lt;p&gt;Of course I should start with the disclaimer that this is a complete hack. But it’s a fun one.&lt;/p&gt;

&lt;p&gt;There’s been a bit of a competition among my friends and me recently as to who can write the best one-liners in python. While I’m by no means in the lead (one of my friends wrote an entire tetris implementation in one line!), I did discover this fun little hack:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;nb&quot;&gt;__import__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;sys&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_getframe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_locals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is gross for a number of reasons. Firstly, the sys.getframe method returns a frame object from the call stack, but this is implementation defined and not guaranteed to work in all versions of python.&lt;/p&gt;

&lt;p&gt;Then, the f_locals field of the frame object is a dictionary of all the local variables in our current stack frame. But since we’re arbitrarily constraining ourselves to expressions (one-liners are cooler this way), we can’t write a line like:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;thisFrame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_locals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;foo&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So we hack it with a builtin destructive dictionary method, update. Since this is ultimately a destructive function call, while this is technically an expression, it evaluates to None.&lt;/p&gt;
</content>
 </entry>
 

</feed>
